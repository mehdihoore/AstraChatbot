{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHz3wZJcca2ioqOMBV2Ekb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdihoore/AstraChatbot/blob/main/telegram_json_processor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<style>\n",
        ".rtl-text {\n",
        "    direction: rtl;\n",
        "    text-align: right;\n",
        "    color: rgb(55, 16, 194);\n",
        "}\n",
        "</style>\n",
        "<div class=\"rtl-text\" dir=rtl>\n",
        "1-\n",
        "فایل خود را در سمت چپ آپلود کنید.\n",
        "</div>\n",
        "<div class=\"rtl-text\" dir=rtl>\n",
        "2-\n",
        " ماژولهای لازم را نصب کنید.\n",
        "</div>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9yv4hYqOsL-7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install telethon datetime khayyam google-generativeai pandas\n",
        "!pip install -U -q \"google-generativeai>=0.7.2\"\n",
        "!pip install Pillow PyPDF2 python-docx numpy\n"
      ],
      "metadata": {
        "id": "7RctaOl5lv5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<style>\n",
        ".rtl-text {\n",
        "    direction: rtl;\n",
        "    text-align: right;\n",
        "    color: rgb(55, 16, 194);\n",
        "}\n",
        "</style>\n",
        "<div class=\"rtl-text\" dir=rtl>\n",
        "3-\n",
        "فایل خود را از زیپ خارج کنید.\n",
        "</div>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b71QFvB8wMqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip json.zip -d extracted_files/"
      ],
      "metadata": {
        "id": "dQ8f-hfim8Xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<style>\n",
        ".rtl-text {\n",
        "    direction: rtl;\n",
        "    text-align: right;\n",
        "    color: rgb(55, 16, 194);\n",
        "}\n",
        "</style>\n",
        "<div class=\"rtl-text\" dir=rtl>\n",
        "4-\n",
        "کد را اجرا کنید.\n",
        "</div>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l4TFIoGiw1Of"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fATNjHDLlKQy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from khayyam import JalaliDate\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "from typing import Optional, Dict, Any, List\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "import io\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import logging\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Configuration for AI processing\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        # Configure Gemini API key\n",
        "        # Replace with your actual API key\n",
        "        self.GEMINI_API_KEY = userdata.get(\"GOOGLE_API_KEY_NHO\")\n",
        "        genai.configure(api_key=self.GEMINI_API_KEY)\n",
        "\n",
        "        # Initialize Gemini models\n",
        "        self.audio_model = genai.GenerativeModel('models/gemini-1.5-flash')\n",
        "        self.chat_model = genai.GenerativeModel('models/gemini-exp-1121')\n",
        "\n",
        "# Columns for the CSV output\n",
        "COLUMNS = [\n",
        "    \"msg_id\",\n",
        "    \"sender\",\n",
        "    \"sender_id\",\n",
        "    \"user_username\",\n",
        "    \"user_first_name\",\n",
        "    \"user_last_name\",\n",
        "    \"user_is_bot\",\n",
        "    \"reply_to_msg_id\",\n",
        "    \"date\",\n",
        "    \"persian_year\",\n",
        "    \"persian_month\",\n",
        "    \"persian_day\",\n",
        "    \"msg_type\",\n",
        "    \"msg_content\",\n",
        "    \"transcription\",\n",
        "    \"doc_summary\",\n",
        "    \"img_description\",\n",
        "    \"img_features\",\n",
        "    \"has_mention\",\n",
        "    \"has_email\",\n",
        "    \"has_phone\",\n",
        "    \"has_hashtag\",\n",
        "    \"is_bot_command\",\n",
        "]\n",
        "\n",
        "persian_months = [\n",
        "    \"فروردین\", \"اردیبهشت\", \"خرداد\", \"تیر\", \"مرداد\", \"شهریور\",\n",
        "    \"مهر\", \"آبان\", \"آذر\", \"دی\", \"بهمن\", \"اسفند\"\n",
        "]\n",
        "\n",
        "class TelegramJSONProcessor:\n",
        "    def __init__(self, config: Config):\n",
        "        self.config = config\n",
        "        self.processed_messages = []\n",
        "        self.json_file_path = None  # Store the path to the JSON file\n",
        "\n",
        "    def process_json_file(self, json_path: str, output_csv_path: str = None):\n",
        "        \"\"\"\n",
        "        Process a JSON file exported from Telegram\n",
        "\n",
        "        :param json_path: Path to the JSON file containing message history\n",
        "        :param output_csv_path: Optional custom output CSV path\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            with open(json_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Ensure we are accessing the \"messages\" key if the JSON is structured\n",
        "            messages_data = data.get(\"messages\", data)\n",
        "\n",
        "            # Determine output path\n",
        "            if not output_csv_path:\n",
        "                output_csv_path = os.path.join(\n",
        "                    self.config.OUTPUT_DIR,\n",
        "                    f\"chat_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "                )\n",
        "\n",
        "            # Process messages\n",
        "            processed_messages = []\n",
        "            for message in messages_data:\n",
        "                if not isinstance(message, dict):\n",
        "                    logger.warning(f\"Skipping non-dictionary item: {message}\")\n",
        "                    continue\n",
        "\n",
        "                processed_msg = self.process_message(message)\n",
        "                if processed_msg:\n",
        "                    processed_messages.append(processed_msg)\n",
        "\n",
        "            # Save to CSV\n",
        "            self.save_to_csv(processed_messages, output_csv_path)\n",
        "\n",
        "            logger.info(f\"Processed {len(processed_messages)} messages. CSV saved to {output_csv_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error processing JSON file: {str(e)}\")\n",
        "\n",
        "\n",
        "    def process_message(self, message: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Process individual message with content analysis\n",
        "\n",
        "        :param message: Message dictionary from JSON\n",
        "        :return: Processed message dictionary\n",
        "        \"\"\"\n",
        "        json_path = '/content/extracted_files/json/result.json'\n",
        "        try:\n",
        "            # Basic message data extraction\n",
        "            msg_data = {\n",
        "                \"msg_id\": message.get('id', 0),\n",
        "                \"sender\": message.get('from_name', ''),\n",
        "                \"sender_id\": message.get('from_id', ''),\n",
        "                \"user_username\": message.get('from_username', None),\n",
        "                \"user_first_name\": message.get('from_name', ''),\n",
        "                \"user_last_name\": None,\n",
        "                \"user_is_bot\": 1 if message.get('from_is_bot', False) else 0,\n",
        "                \"reply_to_msg_id\": message.get('reply_to_message_id'),\n",
        "                \"date\": message.get('date'),\n",
        "                \"persian_year\": 'persian_year',\n",
        "                \"persian_month\": 'persian_month',\n",
        "                \"persian_day\":'persian_day',\n",
        "                \"msg_type\": \"text\",\n",
        "                \"msg_content\": \"\",\n",
        "                \"transcription\": \"\",\n",
        "                \"doc_summary\": \"\",\n",
        "                \"img_description\": \"\",\n",
        "                \"img_features\": \"\",\n",
        "                \"has_mention\": 0,\n",
        "                \"has_email\": 0,\n",
        "                \"has_phone\": 0,\n",
        "                \"has_hashtag\": 0,\n",
        "                \"is_bot_command\": 0\n",
        "            }\n",
        "\n",
        "            # Handle text content\n",
        "            if 'text' in message:\n",
        "                if isinstance(message['text'], list):\n",
        "                    # Concatenate or handle list of text parts\n",
        "                    msg_data['msg_content'] = ''.join(\n",
        "                        part if isinstance(part, str) else '' for part in message['text']\n",
        "                    )\n",
        "                elif isinstance(message['text'], str):\n",
        "                    msg_data['msg_content'] = message['text']\n",
        "                else:\n",
        "                    msg_data['msg_content'] = \"\"\n",
        "\n",
        "                # Update mentions and hashtags detection\n",
        "                msg_data['has_mention'] = 1 if '@' in msg_data['msg_content'] else 0\n",
        "                msg_data['has_hashtag'] = 1 if '#' in msg_data['msg_content'] else 0\n",
        "\n",
        "            # Process media types\n",
        "            if 'photo' in message:\n",
        "                msg_data['msg_type'] = 'image'\n",
        "                photo_path = message.get('photo', '')\n",
        "\n",
        "                # Attempt to process image if file exists\n",
        "                try:\n",
        "                    full_photo_path = os.path.join(os.path.dirname(json_path),  photo_path)\n",
        "                    print(full_photo_path)\n",
        "                    if os.path.exists(full_photo_path):\n",
        "                        img_analysis = self.process_image(\n",
        "                            [{'file_path': full_photo_path}])\n",
        "                        msg_data['img_description'] = img_analysis.get(\n",
        "                            'description', '')\n",
        "                        msg_data['img_features'] = ', '.join(\n",
        "                            img_analysis.get('features', []))\n",
        "                except Exception as img_err:\n",
        "                    logger.warning(f\"Image processing failed: {str(img_err)}\")\n",
        "\n",
        "            elif 'media_type' in message:\n",
        "                msg_data['msg_type'] = 'voice_message'\n",
        "                voice_path = message.get('file', '')\n",
        "                print(\"voice path is:\", voice_path)\n",
        "\n",
        "                # Attempt to transcribe voice message\n",
        "                try:\n",
        "                    full_voice_path = os.path.join(os.path.dirname(json_path), voice_path)\n",
        "                    print(\"voice path is:\", full_voice_path)\n",
        "                    if os.path.exists(full_voice_path):\n",
        "                        transcription = self.transcribe_voice_message(\n",
        "                            {'file_path': full_voice_path})\n",
        "                        msg_data['transcription'] = transcription\n",
        "                        msg_data['msg_content'] = transcription\n",
        "                except Exception as voice_err:\n",
        "                    logger.warning(f\"Voice transcription failed: {str(voice_err)}\")\n",
        "\n",
        "            elif 'mime_type' in message:\n",
        "                msg_data['msg_type'] = 'document'\n",
        "                doc_path = message.get('file', '')\n",
        "\n",
        "                # Attempt to process the document\n",
        "                try:\n",
        "                    full_doc_path = os.path.join(os.path.dirname(json_path), doc_path)\n",
        "                    print(\"full doc path is: \", full_doc_path)\n",
        "                    if os.path.exists(full_doc_path):\n",
        "                        doc_summary = self.process_document(\n",
        "                            {'file_path': full_doc_path})\n",
        "                        msg_data['doc_summary'] = doc_summary\n",
        "                except Exception as doc_err:\n",
        "                    logger.warning(\n",
        "                        f\"Document processing failed: {str(doc_err)}\")\n",
        "\n",
        "            # Regex for email and phone detection\n",
        "            msg_data['has_email'] = 1 if re.search(\n",
        "                r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}', msg_data['msg_content']) else 0\n",
        "            msg_data['has_phone'] = 1 if re.search(\n",
        "                r'\\b(?:\\+?98|0)?9[0-9]{9}\\b', msg_data['msg_content']) else 0\n",
        "            from dateutil.parser import parse  # Import for flexible date parsing\n",
        "            # Convert date to Jalali calendar\n",
        "            if msg_data['date']:\n",
        "                try:\n",
        "                    # Parse ISO 8601 date string\n",
        "                    date_obj = parse(msg_data['date'])\n",
        "                    jalali_date = JalaliDate(date_obj)\n",
        "                    msg_data['persian_year'] = jalali_date.year\n",
        "                    msg_data['persian_month'] = persian_months[jalali_date.month - 1]\n",
        "                    msg_data['persian_day'] = jalali_date.day\n",
        "                except Exception as e:\n",
        "                    logger.warning(f\"Date conversion error: {str(e)}\")\n",
        "                    msg_data['persian_year'] = None\n",
        "                    msg_data['persian_month'] = None\n",
        "                    msg_data['persian_day'] = None\n",
        "\n",
        "            return msg_data\n",
        "            logger.info(f\"Processing message: {message.get('id', 'No ID')}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Detailed error processing message: {str(e)}\")\n",
        "            logger.error(f\"Problematic message: {message}\")\n",
        "            return None\n",
        "\n",
        "    def process_image(self, photo_data: List[Dict]) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Process image using Gemini\n",
        "\n",
        "        :param photo_data: Photo data from JSON\n",
        "        :return: Dictionary with image description and features\n",
        "        \"\"\"\n",
        "        print(\"we are on process_image\")\n",
        "        try:\n",
        "            # Typically, the last item in the photo list is the largest\n",
        "            if not photo_data:\n",
        "                return {\"description\": \"\", \"features\": []}\n",
        "\n",
        "            # Assume the photo is base64 encoded or has a file_path\n",
        "            # You might need to adjust this based on your exact JSON structure\n",
        "            photo = photo_data[-1]\n",
        "            print(\"photo is in proccess: \", photo['file_path'])\n",
        "            # If file path exists, open the image\n",
        "            if 'file_path' in photo:\n",
        "                with Image.open(photo['file_path']) as img:\n",
        "                    # Convert to bytes\n",
        "                    img_byte_arr = io.BytesIO()\n",
        "                    img.save(img_byte_arr, format='JPEG')\n",
        "                    img_byte_arr = img_byte_arr.getvalue()\n",
        "            else:\n",
        "                # If base64 encoded, decode\n",
        "                import base64\n",
        "                img_byte_arr = base64.b64decode(photo.get('base64', ''))\n",
        "\n",
        "            # Generate image description\n",
        "            prompt = \"\"\"Analyze this image and provide:\n",
        "            1. A detailed description\n",
        "            2. Key features or elements present\n",
        "            Respond in plain text format with two sections:\n",
        "            DESCRIPTION:\n",
        "            [Your description here]\n",
        "            FEATURES:\n",
        "            - [feature 1]\n",
        "            - [feature 2]\n",
        "            etc in persian.\"\"\"\n",
        "\n",
        "            # Generate response\n",
        "            generation_config = {\n",
        "                \"temperature\": 1,\n",
        "                \"top_p\": 0.95,\n",
        "                \"top_k\": 64,\n",
        "                \"max_output_tokens\": 8192,\n",
        "\n",
        "            }\n",
        "            response = self.config.audio_model.generate_content(\n",
        "                [prompt, {\n",
        "                    \"mime_type\": \"image/jpeg\",\n",
        "                    \"data\": img_byte_arr\n",
        "                }],\n",
        "                safety_settings={\n",
        "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                },\n",
        "                generation_config=generation_config\n",
        "\n",
        "\n",
        "            )\n",
        "\n",
        "            # Parse response\n",
        "            text = response.text\n",
        "            description = \"\"\n",
        "            features = []\n",
        "\n",
        "            if \"DESCRIPTION:\" in text:\n",
        "                parts = text.split(\"FEATURES:\")\n",
        "                description = parts[0].replace(\"DESCRIPTION:\", \"\").strip()\n",
        "                if len(parts) > 1:\n",
        "                    features = [f.strip(\"- \").strip()\n",
        "                                for f in parts[1].split(\"\\n\") if f.strip()]\n",
        "\n",
        "            return {\n",
        "                \"description\": description,\n",
        "                \"features\": features\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Image processing error: {str(e)}\")\n",
        "            return {\"description\": \"Error processing image\", \"features\": []}\n",
        "\n",
        "\n",
        "    def process_document(self, document_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Process document using Gemini\n",
        "\n",
        "        :param document_data: Document data from JSON\n",
        "        :return: Document summary\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure file path exists\n",
        "            if not document_data.get('file_path'):\n",
        "                return \"No file path found\"\n",
        "\n",
        "            # Determine file type\n",
        "            file_ext = os.path.splitext(document_data['file_path'])[1].lower()\n",
        "\n",
        "            # Read file contents based on type\n",
        "            text_content = \"\"\n",
        "            if file_ext == '.txt':\n",
        "                with open(document_data['file_path'], 'r', encoding='utf-8') as f:\n",
        "                    text_content = f.read()\n",
        "            elif file_ext == '.pdf':\n",
        "                try:\n",
        "                    import PyPDF2\n",
        "                    with open(document_data['file_path'], 'rb') as f:\n",
        "                        pdf_reader = PyPDF2.PdfReader(f)\n",
        "                        text_content = \"\\n\".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])\n",
        "                except Exception as pdf_err:\n",
        "                    logger.error(f\"PDF extraction error: {pdf_err}\")\n",
        "                    text_content = \"\"\n",
        "\n",
        "            # Limit text content\n",
        "            text_content = text_content.strip()[:2000]\n",
        "\n",
        "            # Generate summary\n",
        "            prompt = f\"\"\"Please provide a detailed summary of the following document content in persian: {text_content}\"\"\"\n",
        "\n",
        "            response = self.config.chat_model.generate_content(\n",
        "                prompt,\n",
        "                safety_settings={\n",
        "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            return response.text if response else \"No summary available\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Document processing error: {str(e)}\")\n",
        "            return f\"Error processing document: {str(e)}\"\n",
        "\n",
        "    def transcribe_voice_message(self, voice_data: Dict) -> str:\n",
        "        \"\"\"\n",
        "        Transcribe voice message using Gemini\n",
        "\n",
        "        :param voice_data: Voice message data from JSON\n",
        "        :return: Transcription text\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Ensure file path exists\n",
        "            if not voice_data.get('file_path'):\n",
        "                return \"\"\n",
        "\n",
        "            # Read audio file\n",
        "            with open(voice_data['file_path'], 'rb') as audio_file:\n",
        "                audio_data = audio_file.read()\n",
        "\n",
        "            # Create prompt\n",
        "            prompt = \"Please transcribe this audio file as plain text in Persian (Farsi) language.\"\n",
        "\n",
        "            # Generate transcription\n",
        "            response = self.config.audio_model.generate_content(\n",
        "                [\n",
        "                    prompt,\n",
        "                    {\n",
        "                        \"mime_type\": \"audio/ogg\",\n",
        "                        \"data\": audio_data\n",
        "                    }\n",
        "                ],\n",
        "                safety_settings={\n",
        "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "                },\n",
        "\n",
        "            )\n",
        "\n",
        "            return response.text if response and response.text else \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Voice transcription error: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def save_to_csv(self, messages: List[Dict[str, Any]], output_path: str):\n",
        "        \"\"\"\n",
        "        Save processed messages to CSV\n",
        "\n",
        "        :param messages: List of processed message dictionaries\n",
        "        :param output_path: Path to save CSV file\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Create DataFrame and save to CSV\n",
        "            df = pd.DataFrame(messages)\n",
        "            df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "        except Exception as e:\n",
        "            logger.error(f\"CSV saving error: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    # Initialize configuration\n",
        "    config = Config()\n",
        "    GEMINI_API_KEY = userdata.get(\"GOOGLE_API_KEY\")\n",
        "    # Create processor\n",
        "    processor = TelegramJSONProcessor(config)\n",
        "\n",
        "    # Check if JSON path is provided as command-line argument\n",
        "\n",
        "    json_path = '/content/extracted_files/json/result.json'\n",
        "    output_csv_path = '/content/extracted_files/result.csv'\n",
        "    processor.process_json_file(json_path, output_csv_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<style>\n",
        ".rtl-text {\n",
        "    direction: rtl;\n",
        "    text-align: right;\n",
        "    color: rgb(55, 16, 194);\n",
        "}\n",
        "</style>\n",
        "<div class=\"rtl-text\" dir=rtl>\n",
        "5-\n",
        "فایل csv تولید را چک کنید\n",
        "</div>\n",
        "<div class=\"rtl-text\" dir=rtl>\n",
        "6-\n",
        "برای سوال و جواب این کد را ران کنید.\n",
        "</div>\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "N3B_v3jk-Ug9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import sys\n",
        "import csv\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from khayyam import JalaliDate\n",
        "import google.generativeai as genai\n",
        "import pandas as pd\n",
        "from typing import Optional, Dict, Any, List\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "import io\n",
        "from PIL import Image\n",
        "import tempfile\n",
        "import logging\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "from IPython.display import HTML\n",
        "import sys\n",
        "\n",
        "class ChatHistoryQA:\n",
        "    def __init__(self, api_key):\n",
        "        \"\"\"\n",
        "        Initialize the ChatHistoryQA with Gemini API configuration\n",
        "\n",
        "        :param api_key: Google Gemini API key\n",
        "        \"\"\"\n",
        "        genai.configure(api_key=api_key)\n",
        "        self.chat_model = genai.GenerativeModel('models/gemini-exp-1121')\n",
        "\n",
        "    def create_comprehensive_context(self, df, max_length=10000):\n",
        "        \"\"\"\n",
        "        Create a comprehensive context from the DataFrame\n",
        "\n",
        "        :param df: DataFrame containing chat history\n",
        "        :param max_length: Maximum length of context\n",
        "        :return: Formatted context string\n",
        "        \"\"\"\n",
        "        context_parts = []\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            # Create context entry with multiple details\n",
        "            context_entry = [\n",
        "                f\"پیام {row['msg_id']}\",\n",
        "                f\"فرستنده: {self._get_user_reference(row)}\",\n",
        "                f\"تاریخ شمسی: {int(row['persian_year'])} {row['persian_month']} {int(row['persian_day'])}\",\n",
        "                f\"تاریخ میلادی: {row['date']}\"\n",
        "            ]\n",
        "\n",
        "            # Add content from different message types\n",
        "            if pd.notna(row['msg_content']) and str(row['msg_content']).strip():\n",
        "                context_entry.append(f\"متن پیام: {row['msg_content']}\")\n",
        "\n",
        "            if pd.notna(row['transcription']) and str(row['transcription']).strip():\n",
        "                context_entry.append(f\"رونویسی صوتی: {row['transcription']}\")\n",
        "\n",
        "            if pd.notna(row['doc_summary']) and str(row['doc_summary']).strip():\n",
        "                context_entry.append(f\"خلاصه سند: {row['doc_summary']}\")\n",
        "\n",
        "            if pd.notna(row['img_description']) and str(row['img_description']).strip():\n",
        "                context_entry.append(f\"توصیف تصویر: {row['img_description']}\")\n",
        "\n",
        "            context_parts.append(\" | \".join(context_entry))\n",
        "\n",
        "            # Break if context gets too long\n",
        "            if len(\" \".join(context_parts)) > max_length:\n",
        "                break\n",
        "\n",
        "        return \"\\n\".join(context_parts)\n",
        "\n",
        "    def _get_user_reference(self, row):\n",
        "        \"\"\"\n",
        "        Generate a user reference with privacy protection\n",
        "\n",
        "        :param row: DataFrame row\n",
        "        :return: User reference string\n",
        "        \"\"\"\n",
        "        # Priority 1: Username\n",
        "        if pd.notna(row['user_username']) and str(row['user_username']).strip():\n",
        "            return f\"@{row['user_username']}\"\n",
        "\n",
        "        # Priority 2: Name\n",
        "        name_parts = []\n",
        "        if pd.notna(row['user_first_name']) and str(row['user_first_name']).strip() not in ['.', '']:\n",
        "            name_parts.append(row['user_first_name'])\n",
        "        if pd.notna(row['user_last_name']) and str(row['user_last_name']).strip() not in ['.', '']:\n",
        "            name_parts.append(row['user_last_name'])\n",
        "\n",
        "        if name_parts:\n",
        "            return \" \".join(name_parts)\n",
        "\n",
        "        # Priority 3: Sender ID\n",
        "        if pd.notna(row['sender_id']):\n",
        "            return f\"کاربر {row['sender_id']}\"\n",
        "\n",
        "        # Default\n",
        "        return \"کاربر ناشناس\"\n",
        "\n",
        "    def ask_question(self, csv_path: str, question: str):\n",
        "        \"\"\"\n",
        "        Ask a question about the chat history\n",
        "\n",
        "        :param csv_path: Path to the CSV file\n",
        "        :param question: Question to ask\n",
        "        :return: AI-generated response\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Read CSV file\n",
        "            df = pd.read_csv(csv_path, encoding='utf-8-sig')\n",
        "\n",
        "            # Prepare comprehensive context\n",
        "            context = self.create_comprehensive_context(df)\n",
        "\n",
        "            # Construct prompt\n",
        "            prompt = f\"\"\"System Instructions:\n",
        "            You are an AI assistant analyzing group discussions. Provide detailed analysis based on the available context.\n",
        "\n",
        "            Context of Conversations:\n",
        "            {context}\n",
        "\n",
        "            Question: {question}\n",
        "\n",
        "            Please provide a detailed answer based on the conversation history, citing specific messages or details when possible.\"\"\"\n",
        "\n",
        "            # Generate response\n",
        "            response = self.chat_model.generate_content(\n",
        "                prompt,\n",
        "                generation_config={\n",
        "                    'temperature': 0.3,\n",
        "                    'top_p': 0.8,\n",
        "                },\n",
        "                safety_settings={\n",
        "                    genai.types.HarmCategory.HARM_CATEGORY_HATE_SPEECH: genai.types.HarmBlockThreshold.BLOCK_NONE,\n",
        "                    genai.types.HarmCategory.HARM_CATEGORY_HARASSMENT: genai.types.HarmBlockThreshold.BLOCK_NONE,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            return f\"\\u200F{response.text}\\u200F\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"\\u200Fخطا در پردازش سوال: {str(e)}\\u200F\"\n",
        "\n",
        "# Usage example\n",
        "def main():\n",
        "    # Replace with your actual Google API key\n",
        "    API_KEY = userdata.get(\"GOOGLE_API_KEY_BHR1\")\n",
        "\n",
        "    # Replace with the path to your CSV file\n",
        "    CSV_PATH = \"/content/extracted_files/result.csv\"\n",
        "\n",
        "    # Create QA instance\n",
        "    qa = ChatHistoryQA(API_KEY)\n",
        "\n",
        "    # Interactive Q&A loop\n",
        "    while True:\n",
        "        question_html = HTML(f\"\"\"\n",
        "        <div dir='rtl' style='text-align: right;'>\n",
        "            سوال خود را بپرسید (برای خروج 'exit' را وارد کنید):\n",
        "        </div>\n",
        "        \"\"\")\n",
        "        display(question_html)\n",
        "        question = input()\n",
        "\n",
        "        if question.lower() == 'exit':\n",
        "            break\n",
        "\n",
        "        # Ask question and display response\n",
        "        try:\n",
        "            response = qa.ask_question(CSV_PATH, question)\n",
        "            response_html = HTML(f\"\"\"\n",
        "            <div dir='rtl' style='text-align: right;'>\n",
        "                <h3>پاسخ:</h3>\n",
        "\n",
        "            </div>\n",
        "            <p>حالا در ادامه بشنوید از پاسخ:</p>\n",
        "            <div>{response}</div>\n",
        "            \"\"\")\n",
        "            display(response_html)\n",
        "\n",
        "        except Exception as e:\n",
        "            error_html = HTML(f\"\"\"\n",
        "            <div dir='rtl' style='text-align: right; color: red;'>\n",
        "                <h3>خطا:</h3>\n",
        "                <p>{str(e)}</p>\n",
        "            </div>\n",
        "            \"\"\")\n",
        "            display(error_html)\n",
        "\n",
        "        separator_html = HTML(\"<hr/>\")\n",
        "        display(separator_html)\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "TtsgmjYM-m47"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
